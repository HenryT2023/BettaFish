# -*- coding: utf-8 -*-
"""
Quill Runner â€” æ–‡ç« ç”Ÿæˆ + docx æ¸²æŸ“ + Telegram å‘é€

èŒè´£ï¼š
1. è¯»å– Sage åˆ†æç»“æœï¼ˆJSON + Markdownï¼‰
2. è°ƒç”¨ LLM ç”Ÿæˆå…¬ä¼—å·é£æ ¼å®Œæ•´æ–‡ç« ï¼ˆMarkdownï¼‰
3. docx_renderer â†’ .docx
4. telegram_sender â†’ å‘é€åˆ° Telegram â†’ è§¦å‘ wechat-publisher
5. æ›´æ–° state.json å‘å¸ƒè®¡æ•°

ç”¨æ³•ï¼š
    python quill_runner.py                        # è‡ªåŠ¨å¤„ç†å½“å¤© sage åˆ†æ
    python quill_runner.py --date 20260213        # æŒ‡å®šæ—¥æœŸ
"""

from __future__ import annotations

import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

from loguru import logger

PROJECT_ROOT = Path(__file__).resolve().parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from config import settings
from pipeline_state import (
    can_publish_free,
    increment_publish_count,
    load_state,
    save_state,
)
from telegram_sender import send_document, send_message


def load_sage_analysis(date_str: Optional[str] = None) -> Optional[Dict]:
    """åŠ è½½æŒ‡å®šæ—¥æœŸçš„ Sage åˆ†æ JSON"""
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    json_path = PROJECT_ROOT / "pipeline" / "sage" / f"{date_str}-analysis.json"
    if not json_path.exists():
        logger.warning(f"Sage åˆ†æä¸å­˜åœ¨: {json_path}")
        return None

    try:
        with open(json_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"åŠ è½½ Sage åˆ†æå¤±è´¥: {e}")
        return None


def generate_article_markdown(analysis: Dict) -> str:
    """
    è°ƒç”¨ LLM ç”Ÿæˆå…¬ä¼—å·é£æ ¼å®Œæ•´æ–‡ç« ï¼ˆMarkdown æ ¼å¼ï¼‰ã€‚
    è¾“å…¥ï¼šSage åˆ†æçš„ selected_topic + outlineã€‚
    è¾“å‡ºï¼š1500-3000 å­—çš„ Markdown æ–‡ç« ã€‚
    """
    from openai import OpenAI

    api_key = settings.REPORT_ENGINE_API_KEY or settings.INSIGHT_ENGINE_API_KEY
    base_url = settings.REPORT_ENGINE_BASE_URL or settings.INSIGHT_ENGINE_BASE_URL
    model = settings.REPORT_ENGINE_MODEL_NAME or settings.INSIGHT_ENGINE_MODEL_NAME or "qwen-max"

    if not api_key:
        logger.error("æ— å¯ç”¨ LLM API Keyï¼Œæ— æ³•ç”Ÿæˆæ–‡ç« ")
        return ""

    client = OpenAI(api_key=api_key, base_url=base_url)

    selected = analysis.get("selected_topic", {})
    topic = selected.get("topic", "")
    headlines = selected.get("headlines", [])
    outline = selected.get("outline", [])
    evidence = selected.get("evidence", [])
    forum_summary = analysis.get("forum_summary", "")
    info_gap = analysis.get("info_gap_analysis", {})

    # æ„å»ºå¤§çº²æ–‡æœ¬
    outline_text = ""
    if isinstance(outline, list):
        for i, section in enumerate(outline):
            if isinstance(section, dict):
                refs = section.get("evidence_refs", [])
                ref_str = f" [è¯æ®: {refs}]" if refs else ""
                outline_text += f"{i+1}. {section.get('title', '')}: {section.get('points', section.get('content', ''))}{ref_str}\n"
            elif isinstance(section, str):
                outline_text += f"{i+1}. {section}\n"
    elif isinstance(outline, str):
        outline_text = outline

    # æ„å»ºè¯æ®å—æ–‡æœ¬
    evidence_text = ""
    if evidence:
        for ev in evidence:
            evidence_text += (
                f"[è¯æ®{ev.get('ref_id', '?')}] {ev.get('source_title', '')}\n"
                f"  URL: {ev.get('source_url', '')}\n"
                f"  åŸæ–‡: {ev.get('quote', '')}\n"
                f"  å¯éªŒè¯äº‹å®: {', '.join(ev.get('verifiable_facts', []))}\n\n"
            )

    # ä¿¡æ¯å·®åˆ†ææ–‡æœ¬
    gap_text = ""
    if info_gap:
        gap_text = (
            f"æµ·å¤–è§†è§’: {info_gap.get('international_view', '')}\n"
            f"å›½å†…è§†è§’: {info_gap.get('domestic_view', '')}\n"
            f"ä¿¡æ¯å·®æ´å¯Ÿ: {info_gap.get('gap_insight', '')}"
        )

    # å¤šè§†è§’å‚è€ƒ
    forum_text = ""
    if forum_summary:
        if isinstance(forum_summary, dict):
            for agent, view in forum_summary.items():
                forum_text += f"- {agent}: {view}\n"
        else:
            forum_text = str(forum_summary)

    system_prompt = """ä½ æ˜¯ä¸€ä¸ªåœ¨è·¨å¢ƒç”µå•†åœˆæ··äº†åå¹´çš„äººï¼Œé å†™å…¬ä¼—å·å…»æ´»äº†ä¸€ä¸ªå°å›¢é˜Ÿã€‚ä½ çš„å·å«ã€Œä¸œæ—ºæ•°è´¸ã€ï¼Œç²‰ä¸ä¸å¤šä½†é»æ€§æå¼ºï¼Œå› ä¸ºä½ åªå†™ä½ çœŸæ­£æ‡‚çš„ä¸œè¥¿ã€‚

## ä½ çš„äººè®¾
- ä½ åœ¨æ·±åœ³åå¼ºåŒ—å¾…è¿‡ï¼Œåšè¿‡äºšé©¬é€Šï¼Œç°åœ¨ä¸»è¦ç ”ç©¶AIå·¥å…·æ€ä¹ˆå¸®å–å®¶çœé’±
- ä½ è¯´è¯ç›´æ¥ï¼Œå¶å°”æ¯’èˆŒï¼Œä½†æ•°æ®ä¸€å®šå‡†
- ä½ æœ€è®¨åŒçš„æ–‡ç« ç±»å‹ï¼šã€Œä¸€æ–‡è¯»æ‡‚XXXã€ã€Œå…¨é¢è§£æXXXã€ã€Œç›˜ç‚¹2026å¹´åå¤§è¶‹åŠ¿ã€
- ä½ å†™æ–‡ç« åƒåœ¨å¾®ä¿¡ç¾¤é‡Œç»™æœ‹å‹å‘è¯­éŸ³ï¼Œåªä¸è¿‡æ•´ç†æˆäº†æ–‡å­—

## å†™æ³•
- å¼€å¤´30å­—å†…å¿…é¡»å‡ºç°ä¸€ä¸ªå…·ä½“çš„æ•°å­—ã€äººåæˆ–äº‹ä»¶ï¼Œä¸è¦ä»»ä½•é“ºå«
- æ®µè½æœ€å¤š3å¥ã€‚è¶…è¿‡3å¥å°±æ‹†
- å°æ ‡é¢˜è¦æœ‰æ€åº¦ï¼Œä¸è¦æè¿°æ€§æ ‡é¢˜ã€‚æ¯”å¦‚"Temuçš„ç®—ç›˜æ²¡æ‰“å“"è€Œä¸æ˜¯"Temuè¿‘æœŸå‘å±•åˆ†æ"
- å¦‚æœä½ è¦å¼•ç”¨æ•°æ®ï¼Œç›´æ¥è¯´æ¥æºï¼ˆ"æ ¹æ®Marketplace Pulseä¸Šå‘¨çš„æ•°æ®"ï¼‰ï¼Œä¸è¦"æ®ç»Ÿè®¡""æœ‰æ•°æ®æ˜¾ç¤º"
- å…è®¸å‡ºç°ä¸€ä¸¤å¥è„è¯çº§åˆ«çš„å£è¯­ï¼ˆ"è¯´ç™½äº†å°±æ˜¯å‰²éŸ­èœ""è¿™ç©æ„å„¿å°±æ˜¯æ¢çš®"ï¼‰
- æ–‡ç« é‡Œæœ‰ä¸”åªæœ‰ä¸€ä¸ªè¡¨æ ¼ï¼Œæ”¾åœ¨æœ€èƒ½å½¢æˆå¯¹æ¯”å†²å‡»çš„ä½ç½®
- å…¨æ–‡ä¸è¶…è¿‡2000å­—ã€‚å†™å®Œå¦‚æœè¶…äº†ï¼Œç æ‰æœ€å¼±çš„ä¸€èŠ‚

## ç»“æ„
1. æ ‡é¢˜ï¼šä»å€™é€‰ä¸­é€‰æœ€å¥½çš„æˆ–æ”¹å†™ï¼ˆ20å­—ä»¥å†…ï¼‰ï¼Œä»¥ # å¼€å¤´
2. å¼€å¤´ï¼šä¸€ä¸ªå…·ä½“äº‹å®æˆ–åœºæ™¯ï¼Œ30-50å­—ï¼Œç›´æ¥è¿›
3. æ­£æ–‡3-4ä¸ªå°èŠ‚ï¼Œç”¨ ## å°æ ‡é¢˜ï¼Œå°æ ‡é¢˜å¿…é¡»æœ‰è§‚ç‚¹
4. å…³é”®æ•°æ®ç”¨ **åŠ ç²—**ï¼Œåªèƒ½æ¥è‡ªè¯æ®å—
5. ç»“å°¾åªå†™ä¸¤ä»¶äº‹ï¼šä½ çš„ä¸€å¥åˆ¤æ–­ + ä¸€ä¸ªåé—®ã€‚ä¸è¦æ€»ç»“ï¼Œä¸è¦å‡å
6. è¾“å‡ºçº¯ Markdownï¼Œä¸è¦ä»£ç å—åŒ…è£¹

## ç»å¯¹ä¸èƒ½å‡ºç°çš„è¯å’Œå¥å¼
"éšç€" "åœ¨å½“ä»Š" "å€¼å¾—æ³¨æ„çš„æ˜¯" "ä¸å¯å¦è®¤" "æ¯‹åº¸ç½®ç–‘" "ä¼—æ‰€å‘¨çŸ¥"
"è®©æˆ‘ä»¬" "æœ¬æ–‡å°†" "ç»¼ä¸Šæ‰€è¿°" "æ€»è€Œè¨€ä¹‹" "äº‹å®ä¸Š" "æ˜¾è€Œæ˜“è§"
"é¦–å…ˆ...å…¶æ¬¡...æœ€å" "ä¸€æ–¹é¢...å¦ä¸€æ–¹é¢"
"ä¸ºXXXæä¾›äº†æ–°çš„æ€è·¯" "å¯¹XXXå…·æœ‰é‡è¦æ„ä¹‰" "ä¸ºXXXæ³¨å…¥æ–°åŠ¨èƒ½"
"æ®ç»Ÿè®¡" "æ®æŠ¥å‘Š" "æ®äº†è§£" "æœ‰æ•°æ®æ˜¾ç¤º"
ä»»ä½•ä»¥"åœ¨"å­—å¼€å¤´çš„æ®µè½
ç¦æ­¢ç¼–é€ æ•°å­—/é‡‘é¢/ç™¾åˆ†æ¯”â€”â€”åªèƒ½å¼•ç”¨è¯æ®å—ä¸­çš„ verifiable_facts
ç¦æ­¢æ¯æ®µéƒ½ç”¨ç›¸åŒå¥å¼å¼€å¤´
ç¦æ­¢åœ¨æ¯èŠ‚ç»“å°¾éƒ½åˆ—3æ¡ bullet"""

    user_prompt = f"""è¯é¢˜ï¼š{topic}

æ ‡é¢˜å€™é€‰ï¼š
{chr(10).join(f'{i+1}. {h}' for i, h in enumerate(headlines))}

æ–‡ç« å¤§çº²ï¼š
{outline_text}

=== è¯æ®å—ï¼ˆå†™ä½œæ—¶åªèƒ½å¼•ç”¨è¿™äº›äº‹å®ï¼‰===
{evidence_text if evidence_text else "ï¼ˆæ— ç»“æ„åŒ–è¯æ®ï¼Œè¯·åŸºäºå¤§çº²å†…å®¹å†™ä½œï¼Œä¸è¦ç¼–é€ æ•°æ®ï¼‰"}

=== ä¿¡æ¯å·®åˆ†æ ===
{gap_text if gap_text else "ï¼ˆæ— ä¿¡æ¯å·®åˆ†æï¼‰"}

=== å¤šè§†è§’å‚è€ƒ ===
{forum_text}

è¯·æ’°å†™1500-2500å­—çš„å…¬ä¼—å·æ–‡ç« ï¼ˆMarkdown æ ¼å¼ï¼‰ã€‚"""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt[:20000]},
            ],
            temperature=0.7,
            timeout=180,
        )
        content = response.choices[0].message.content.strip()

        # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹
        if content.startswith("```markdown"):
            content = content[len("```markdown"):].strip()
        if content.startswith("```"):
            content = content[3:].strip()
        if content.endswith("```"):
            content = content[:-3].strip()

        return content

    except Exception as e:
        logger.error(f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {e}")
        return ""


def _import_docx_renderer():
    """ç›´æ¥åŠ è½½ docx_renderer æ¨¡å—ï¼Œç»•è¿‡ ReportEngine/__init__ çš„é‡ä¾èµ–é“¾"""
    import importlib.util
    spec = importlib.util.spec_from_file_location(
        "docx_renderer",
        str(PROJECT_ROOT / "ReportEngine" / "renderers" / "docx_renderer.py"),
    )
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)
    return mod.DocxRenderer


def render_docx(markdown_text: str, output_path: str, image_paths: Optional[List[str]] = None) -> Optional[str]:
    """å°† Markdown æ–‡æœ¬æ¸²æŸ“ä¸º .docxï¼Œå¯é€‰æ’å…¥å›¾ç‰‡"""
    try:
        DocxRenderer = _import_docx_renderer()
        renderer = DocxRenderer()
        renderer.render_from_markdown(markdown_text)

        # æ’å…¥å›¾ç‰‡ï¼ˆå°é¢å›¾ + æ•°æ®å›¾ + å…³ç³»å›¾ï¼‰
        if image_paths:
            valid_images = [p for p in image_paths if Path(p).exists()]
            if valid_images:
                renderer.insert_images(valid_images)
                logger.info(f"å·²æ’å…¥ {len(valid_images)} å¼ å›¾ç‰‡åˆ° DOCX")

        renderer.save(output_path)
        return output_path

    except Exception as e:
        logger.error(f"DOCX æ¸²æŸ“å¤±è´¥: {e}")
        return None


def run_quill(date_str: Optional[str] = None, image_paths: Optional[List[str]] = None) -> Optional[str]:
    """
    æ‰§è¡Œ Quillï¼šç”Ÿæˆæ–‡ç«  â†’ docxï¼ˆå«å›¾ç‰‡ï¼‰â†’ å‘é€ Telegramã€‚
    è¿”å› .docx æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› Noneã€‚
    """
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    logger.info(f"=== Quill å¼€å§‹ | date={date_str} ===")

    # 0. æ£€æŸ¥æ¯æ—¥å‘å¸ƒé¢åº¦
    state = load_state()
    if not can_publish_free(state):
        logger.warning("ä»Šæ—¥å…è´¹æ–‡ç« é¢åº¦å·²ç”¨å®Œï¼Œè·³è¿‡")
        return None

    # 1. åŠ è½½ Sage åˆ†æ
    analysis = load_sage_analysis(date_str)
    if not analysis:
        logger.warning("æ—  Sage åˆ†ææ•°æ®ï¼ŒQuill è·³è¿‡")
        return None

    selected = analysis.get("selected_topic", {})
    topic = selected.get("topic", "")
    if not topic:
        logger.warning("Sage æœªé€‰å®šè¯é¢˜ï¼Œè·³è¿‡")
        return None

    logger.info(f">>> è¯é¢˜: {topic}")

    # 2. ç”Ÿæˆæ–‡ç« 
    logger.info(">>> ç”Ÿæˆæ–‡ç« ...")
    article_md = generate_article_markdown(analysis)
    if not article_md or len(article_md) < 500:
        logger.warning(f"æ–‡ç« å†…å®¹è¿‡çŸ­ ({len(article_md)} å­—)ï¼Œè·³è¿‡")
        return None

    logger.info(f">>> æ–‡ç« ç”Ÿæˆå®Œæˆ: {len(article_md)} å­—")

    # 3. ä¿å­˜ Markdown å¤‡ä»½
    md_backup = PROJECT_ROOT / "pipeline" / "drafts" / f"{date_str}-article.md"
    md_backup.parent.mkdir(parents=True, exist_ok=True)
    with open(md_backup, "w", encoding="utf-8") as f:
        f.write(article_md)

    # 4. æ¸²æŸ“ docxï¼ˆå«å›¾ç‰‡ï¼‰
    docx_path = str(PROJECT_ROOT / "pipeline" / "drafts" / f"{date_str}-article.docx")
    logger.info(f">>> æ¸²æŸ“ DOCX...ï¼ˆå›¾ç‰‡: {len(image_paths or [])} å¼ ï¼‰")
    result = render_docx(article_md, docx_path, image_paths=image_paths)
    if not result:
        logger.error("DOCX æ¸²æŸ“å¤±è´¥")
        return None

    logger.info(f">>> DOCX å·²ä¿å­˜: {docx_path}")

    # 5. å‘é€åˆ° Telegram
    # æå–æ ‡é¢˜ï¼ˆMarkdown ç¬¬ä¸€è¡Œ # å¼€å¤´ï¼‰
    title = topic
    for line in article_md.split("\n"):
        line = line.strip()
        if line.startswith("# "):
            title = line[2:].strip()
            break

    word_count = len(article_md)
    caption = f"ğŸ“„ {title}ï¼ˆ{word_count}å­—ï¼‰"
    logger.info(">>> å‘é€åˆ° Telegram...")
    sent = send_document(docx_path, caption=caption)
    if sent:
        logger.info(">>> Telegram å‘é€æˆåŠŸ")
    else:
        logger.warning(">>> Telegram å‘é€å¤±è´¥ï¼ˆæ–‡ç« å·²ä¿å­˜ï¼Œå¯æ‰‹åŠ¨å‘é€ï¼‰")

    # 6. ç”Ÿæˆä»˜è´¹åŠ æ–™ premium-addon
    _generate_premium_addon(analysis, date_str, title)

    # 7. è§¦å‘ wechat-publisher åˆ›å»ºå…¬ä¼—å·è‰ç¨¿
    _trigger_wechat_publisher(docx_path)

    # 8. æ›´æ–°å‘å¸ƒè®¡æ•°
    state = load_state()
    increment_publish_count(state)
    save_state(state)

    logger.info(f"=== Quill å®Œæˆ | {docx_path} ===")
    return docx_path


def _generate_premium_addon(analysis: Dict, date_str: str, title: str):
    """ç”Ÿæˆä»˜è´¹åŠ æ–™ premium-addon.mdï¼ˆ300-800å­—ï¼šæ•°æ®è¡¨+è¡ŒåŠ¨æ¸…å•+èµ„æºé“¾æ¥ï¼‰"""
    from openai import OpenAI

    api_key = settings.REPORT_ENGINE_API_KEY or settings.INSIGHT_ENGINE_API_KEY
    base_url = settings.REPORT_ENGINE_BASE_URL or settings.INSIGHT_ENGINE_BASE_URL
    model = settings.REPORT_ENGINE_MODEL_NAME or settings.INSIGHT_ENGINE_MODEL_NAME or "qwen-max"

    if not api_key:
        logger.info("æ—  LLM API Keyï¼Œè·³è¿‡ premium-addon ç”Ÿæˆ")
        return

    selected = analysis.get("selected_topic", {})
    evidence = selected.get("evidence", [])
    info_gap = analysis.get("info_gap_analysis", {})
    outline = selected.get("outline", [])

    evidence_text = ""
    for ev in evidence:
        evidence_text += f"- [{ev.get('source_title', '')}]({ev.get('source_url', '')}): {ev.get('quote', '')}\n"
        evidence_text += f"  äº‹å®: {', '.join(ev.get('verifiable_facts', []))}\n"

    prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½"ä¼šå‘˜åŠ æ–™"å†…å®¹ï¼ˆMarkdown æ ¼å¼ï¼Œ300-800å­—ï¼‰ã€‚

è¯é¢˜ï¼š{title}
ä¿¡æ¯å·®æ´å¯Ÿï¼š{info_gap.get('gap_insight', '')}

è¯æ®æ¥æºï¼š
{evidence_text}

è¦æ±‚è¾“å‡ºç»“æ„ï¼š
## ğŸ“Š æ•°æ®å¯¹æ¯”è¡¨
ï¼ˆç”¨ Markdown è¡¨æ ¼ï¼Œæµ·å¤– vs å›½å†… å¯¹æ¯”å…³é”®æŒ‡æ ‡ï¼‰

## âœ… è¡ŒåŠ¨æ¸…å•
ï¼ˆ5æ¡å¯æ‰§è¡Œæ­¥éª¤ï¼Œæ¯æ¡1å¥è¯ï¼Œå…·ä½“å¯æ“ä½œï¼‰

## ğŸ”— å»¶ä¼¸èµ„æº
ï¼ˆ3-5ä¸ªé“¾æ¥ï¼Œæ¥è‡ªè¯æ®çš„åŸå§‹ URLï¼Œé™„ç®€è¦è¯´æ˜ï¼‰

## ğŸ’¡ æ·±åº¦æ´å¯Ÿ
ï¼ˆ1æ®µ100å­—çš„ç‹¬å®¶åˆ†æï¼Œåªåœ¨ä¼šå‘˜ç‰ˆå‡ºç°ï¼‰

åªè¾“å‡º Markdownï¼Œä¸è¦ä»£ç å—åŒ…è£¹ã€‚"""

    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            timeout=60,
        )
        addon_md = response.choices[0].message.content.strip()
        if addon_md.startswith("```"):
            addon_md = addon_md.split("\n", 1)[-1]
        if addon_md.endswith("```"):
            addon_md = addon_md[:-3].strip()

        # ä¿å­˜
        addon_path = PROJECT_ROOT / "pipeline" / "drafts" / f"{date_str}-premium-addon.md"
        addon_path.parent.mkdir(parents=True, exist_ok=True)
        with open(addon_path, "w", encoding="utf-8") as f:
            f.write(f"# ä¼šå‘˜åŠ æ–™ | {title}\n\n{addon_md}")

        logger.info(f">>> Premium addon å·²ä¿å­˜: {addon_path} ({len(addon_md)} å­—)")

        # å‘é€åˆ° Premium Telegram é¢‘é“ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        paid_chat_id = getattr(settings, "PAID_TELEGRAM_CHAT_ID", None) or os.getenv("PAID_TELEGRAM_CHAT_ID", "")
        if paid_chat_id:
            from telegram_sender import send_message
            send_message(f"ğŸ”’ ä¼šå‘˜åŠ æ–™ | {title}\n\n{addon_md[:3000]}", chat_id=paid_chat_id)
            logger.info(">>> Premium addon å·²å‘é€åˆ°ä¼šå‘˜é¢‘é“")
        else:
            logger.info(">>> PAID_TELEGRAM_CHAT_ID æœªé…ç½®ï¼Œè·³è¿‡ä¼šå‘˜é¢‘é“æŠ•é€’")

    except Exception as e:
        logger.warning(f"Premium addon ç”Ÿæˆå¤±è´¥: {e}")


def _trigger_wechat_publisher(docx_path: str):
    """ç›´æ¥è°ƒç”¨ wechat_publisher_cron.py --file åˆ›å»ºå…¬ä¼—å·è‰ç¨¿"""
    import subprocess
    wechat_script = Path.home() / "CascadeProjects" / "wechat_publisher_cron.py"
    if not wechat_script.exists():
        logger.info("wechat_publisher_cron.py ä¸å­˜åœ¨ï¼Œè·³è¿‡å…¬ä¼—å·å‘å¸ƒ")
        return
    try:
        logger.info(">>> è§¦å‘ wechat-publisher åˆ›å»ºå…¬ä¼—å·è‰ç¨¿...")
        result = subprocess.run(
            ["/usr/bin/python3", str(wechat_script), "--file", docx_path],
            capture_output=True, text=True, timeout=120,
            cwd=str(wechat_script.parent),
        )
        if result.returncode == 0:
            logger.info(">>> wechat-publisher æ‰§è¡ŒæˆåŠŸ")
            if result.stdout:
                for line in result.stdout.strip().split("\n")[-5:]:
                    logger.info(f"    {line}")
        else:
            logger.warning(f">>> wechat-publisher è¿”å›ç  {result.returncode}")
            if result.stderr:
                logger.warning(f"    {result.stderr[:300]}")
    except subprocess.TimeoutExpired:
        logger.warning(">>> wechat-publisher è¶…æ—¶ (120s)")
    except Exception as e:
        logger.warning(f">>> wechat-publisher è°ƒç”¨å¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description="Quill Runner - æ–‡ç« ç”Ÿæˆ")
    parser.add_argument("--date", type=str, help="ç›®æ ‡æ—¥æœŸ (YYYYMMDD)")
    args = parser.parse_args()

    result = run_quill(date_str=args.date)
    if result:
        print(f"Quill å®Œæˆ: {result}")
    else:
        print("Quill å®Œæˆ: æ— è¾“å‡º")


if __name__ == "__main__":
    main()
