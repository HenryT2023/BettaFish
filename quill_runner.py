# -*- coding: utf-8 -*-
"""
Quill Runner â€” æ–‡ç« ç”Ÿæˆ + docx æ¸²æŸ“ + Telegram å‘é€

èŒè´£ï¼š
1. è¯»å– Sage åˆ†æç»“æœï¼ˆJSON + Markdownï¼‰
2. è°ƒç”¨ LLM ç”Ÿæˆå…¬ä¼—å·é£æ ¼å®Œæ•´æ–‡ç« ï¼ˆMarkdownï¼‰
3. docx_renderer â†’ .docx
4. telegram_sender â†’ å‘é€åˆ° Telegram â†’ è§¦å‘ wechat-publisher
5. æ›´æ–° state.json å‘å¸ƒè®¡æ•°

ç”¨æ³•ï¼š
    python quill_runner.py                        # è‡ªåŠ¨å¤„ç†å½“å¤© sage åˆ†æ
    python quill_runner.py --date 20260213        # æŒ‡å®šæ—¥æœŸ
"""

from __future__ import annotations

import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

from loguru import logger

PROJECT_ROOT = Path(__file__).resolve().parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from config import settings
from pipeline_state import (
    can_publish_free,
    increment_publish_count,
    load_state,
    save_state,
)
from telegram_sender import send_document, send_message


def load_sage_analysis(date_str: Optional[str] = None) -> Optional[Dict]:
    """åŠ è½½æŒ‡å®šæ—¥æœŸçš„ Sage åˆ†æ JSON"""
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    json_path = PROJECT_ROOT / "pipeline" / "sage" / f"{date_str}-analysis.json"
    if not json_path.exists():
        logger.warning(f"Sage åˆ†æä¸å­˜åœ¨: {json_path}")
        return None

    try:
        with open(json_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"åŠ è½½ Sage åˆ†æå¤±è´¥: {e}")
        return None


def generate_article_markdown(analysis: Dict) -> str:
    """
    è°ƒç”¨ LLM ç”Ÿæˆå…¬ä¼—å·é£æ ¼å®Œæ•´æ–‡ç« ï¼ˆMarkdown æ ¼å¼ï¼‰ã€‚
    è¾“å…¥ï¼šSage åˆ†æçš„ selected_topic + outlineã€‚
    è¾“å‡ºï¼š1500-3000 å­—çš„ Markdown æ–‡ç« ã€‚
    """
    from openai import OpenAI

    api_key = settings.REPORT_ENGINE_API_KEY or settings.INSIGHT_ENGINE_API_KEY
    base_url = settings.REPORT_ENGINE_BASE_URL or settings.INSIGHT_ENGINE_BASE_URL
    model = settings.REPORT_ENGINE_MODEL_NAME or settings.INSIGHT_ENGINE_MODEL_NAME or "qwen-max"

    if not api_key:
        logger.error("æ— å¯ç”¨ LLM API Keyï¼Œæ— æ³•ç”Ÿæˆæ–‡ç« ")
        return ""

    client = OpenAI(api_key=api_key, base_url=base_url)

    selected = analysis.get("selected_topic", {})
    topic = selected.get("topic", "")
    headlines = selected.get("headlines", [])
    outline = selected.get("outline", [])
    evidence = selected.get("evidence", [])
    forum_summary = analysis.get("forum_summary", "")
    info_gap = analysis.get("info_gap_analysis", {})

    # æ„å»ºå¤§çº²æ–‡æœ¬
    outline_text = ""
    if isinstance(outline, list):
        for i, section in enumerate(outline):
            if isinstance(section, dict):
                refs = section.get("evidence_refs", [])
                ref_str = f" [è¯æ®: {refs}]" if refs else ""
                outline_text += f"{i+1}. {section.get('title', '')}: {section.get('points', section.get('content', ''))}{ref_str}\n"
            elif isinstance(section, str):
                outline_text += f"{i+1}. {section}\n"
    elif isinstance(outline, str):
        outline_text = outline

    # æ„å»ºè¯æ®å—æ–‡æœ¬
    evidence_text = ""
    if evidence:
        for ev in evidence:
            evidence_text += (
                f"[è¯æ®{ev.get('ref_id', '?')}] {ev.get('source_title', '')}\n"
                f"  URL: {ev.get('source_url', '')}\n"
                f"  åŸæ–‡: {ev.get('quote', '')}\n"
                f"  å¯éªŒè¯äº‹å®: {', '.join(ev.get('verifiable_facts', []))}\n\n"
            )

    # ä¿¡æ¯å·®åˆ†ææ–‡æœ¬
    gap_text = ""
    if info_gap:
        gap_text = (
            f"æµ·å¤–è§†è§’: {info_gap.get('international_view', '')}\n"
            f"å›½å†…è§†è§’: {info_gap.get('domestic_view', '')}\n"
            f"ä¿¡æ¯å·®æ´å¯Ÿ: {info_gap.get('gap_insight', '')}"
        )

    # å¤šè§†è§’å‚è€ƒ
    forum_text = ""
    if forum_summary:
        if isinstance(forum_summary, dict):
            for agent, view in forum_summary.items():
                forum_text += f"- {agent}: {view}\n"
        else:
            forum_text = str(forum_summary)

    system_prompt = """ä½ æ˜¯ä¸€ä¸ªå†™äº†åå¹´è·¨å¢ƒç”µå•†æŠ¥é“çš„è€è®°è€…ï¼Œç°åœ¨ç»™ã€Œä¸œæ—ºæ•°è´¸ã€å…¬ä¼—å·å†™æ·±åº¦è¯„è®ºã€‚
ä½ çš„è¯»è€…éƒ½æ˜¯åœˆå†…äººâ€”â€”è·¨å¢ƒå–å®¶ã€SaaS åˆ›ä¸šè€…ã€å…³æ³¨ AI å·¥å…·çš„å®æ“æ´¾ã€‚ä»–ä»¬è®¨åŒç©ºè¯ï¼Œå–œæ¬¢å¹²è´§å’ŒçœŸå®æ¡ˆä¾‹ã€‚

## å†™ä½œé£æ ¼ï¼ˆæœ€é‡è¦ï¼‰
- åƒåœ¨è·Ÿä¸€ä¸ªåŒè¡Œæœ‹å‹èŠå¤©ï¼Œä¸æ˜¯åœ¨å†™è®ºæ–‡
- ç”¨çŸ­å¥ï¼Œå°‘ç”¨ä»å¥åµŒå¥—ã€‚æ®µè½ä¸è¶…è¿‡4å¥
- å¼€å¤´ç›´æ¥æŠ›ä¸€ä¸ªè®©äººæ„å¤–çš„äº‹å®æˆ–åå¸¸è¯†è§‚ç‚¹ï¼Œä¸è¦"éšç€XXXçš„å‘å±•"
- å¯ä»¥ç”¨åé—®ã€è®¾é—®ã€ç±»æ¯”ï¼Œä½†ä¸è¦æ¯æ®µéƒ½ç”¨
- é€‚å½“åŠ å…¥"è¯´å®è¯""ä½ å¯èƒ½æ²¡æ³¨æ„åˆ°""è¿™ä»¶äº‹æœ‰æ„æ€çš„åœ°æ–¹åœ¨äº"è¿™ç±»å£è¯­è¿æ¥è¯
- å¶å°”è¡¨è¾¾ä½ çš„åˆ¤æ–­å’Œæ€åº¦ï¼Œä¸è¦æ°¸è¿œå®¢è§‚ä¸­ç«‹

## ç»“æ„è¦æ±‚
1. æ ‡é¢˜ï¼šä»å€™é€‰ä¸­é€‰æœ€å¥½çš„æˆ–æ”¹å†™ï¼ˆ20å­—ä»¥å†…ï¼‰ï¼Œä»¥ # å¼€å¤´
2. å¼€å¤´ï¼šä¸€ä¸ªå…·ä½“äº‹å®æˆ–åœºæ™¯åˆ‡å…¥ï¼Œ50-80å­—ï¼Œä¸è¦å†™"å¯¼è¯­"æ„Ÿçš„ä¸œè¥¿
3. æ­£æ–‡åˆ†3-5ä¸ªå°èŠ‚ï¼Œç”¨ ## å°æ ‡é¢˜ï¼Œå°æ ‡é¢˜è¦æœ‰è§‚ç‚¹ä¸è¦åªæ˜¯æè¿°
4. æ¯èŠ‚è‡ªç„¶å±•å¼€ï¼Œåƒåœ¨è®²ä¸€ä¸ªæ•…äº‹æˆ–æ¨ç†ä¸€ä¸ªé€»è¾‘ï¼Œä¸è¦å›ºå®šæ¨¡æ¿
5. ç©¿æ’è‡³å°‘1ä¸ª Markdown å¯¹æ¯”è¡¨æ ¼ï¼Œæ”¾åœ¨æœ€èƒ½è¯´æ˜é—®é¢˜çš„ä½ç½®
6. å…³é”®æ•°æ®ç”¨ **åŠ ç²—**ï¼Œæ•°æ®åªèƒ½æ¥è‡ªè¯æ®å—
7. ç»“å°¾ï¼šä½ çš„ä¸€å¥åˆ¤æ–­ + ä¸€ä¸ªå¼€æ”¾æ€§é—®é¢˜ + ä¸€å¥"æ›´å¤šæ•°æ®å’Œè¡ŒåŠ¨æ¸…å•ï¼Œè§ä¼šå‘˜é¢‘é“"
8. æ€»é•¿ **1500-2500 å­—**ï¼ˆç¡¬æ€§è¦æ±‚ï¼‰
9. è¾“å‡ºçº¯ Markdownï¼Œä¸è¦ä»£ç å—åŒ…è£¹

## ç»å¯¹ç¦æ­¢ï¼ˆè¿åä»»ä½•ä¸€æ¡ç›´æ¥ä¸åˆæ ¼ï¼‰
- ç¦æ­¢ç¼–é€ æ•°å­—/é‡‘é¢/ç™¾åˆ†æ¯”â€”â€”åªèƒ½å¼•ç”¨è¯æ®å—ä¸­çš„ verifiable_facts
- ç¦æ­¢"æ®ç»Ÿè®¡""æ®æŠ¥å‘Š""æ®äº†è§£"ç­‰æ¨¡ç³Šå¼•ç”¨ï¼Œå¿…é¡»å†™æ¸…æ¥šæ¥æº
- ç¦æ­¢è¿™äº› AI å‘³å¥å¼ï¼š
  "åœ¨å½“ä»ŠXXXæ—¶ä»£" / "éšç€XXXçš„å¿«é€Ÿå‘å±•" / "å€¼å¾—æ³¨æ„çš„æ˜¯" /
  "è®©æˆ‘ä»¬ä¸€èµ·æ¥çœ‹çœ‹" / "ä¸å¯å¦è®¤" / "æ¯‹åº¸ç½®ç–‘" /
  "æœ¬æ–‡å°†ä»‹ç»/æ¢è®¨" / "æ€»ä¹‹/ç»¼ä¸Šæ‰€è¿°" / "æ€»è€Œè¨€ä¹‹" /
  "ä¼—æ‰€å‘¨çŸ¥" / "äº‹å®ä¸Š" / "æ˜¾è€Œæ˜“è§" /
  "é¦–å…ˆ...å…¶æ¬¡...æœ€å" ä¸‰æ®µå¼ / "ä¸€æ–¹é¢...å¦ä¸€æ–¹é¢"
- ç¦æ­¢æ¯æ®µéƒ½ç”¨ç›¸åŒå¥å¼å¼€å¤´
- ç¦æ­¢åœ¨æ¯èŠ‚ç»“å°¾éƒ½åˆ—3æ¡ bulletâ€”â€”åªåœ¨çœŸæ­£éœ€è¦çš„åœ°æ–¹åˆ—"""

    user_prompt = f"""è¯é¢˜ï¼š{topic}

æ ‡é¢˜å€™é€‰ï¼š
{chr(10).join(f'{i+1}. {h}' for i, h in enumerate(headlines))}

æ–‡ç« å¤§çº²ï¼š
{outline_text}

=== è¯æ®å—ï¼ˆå†™ä½œæ—¶åªèƒ½å¼•ç”¨è¿™äº›äº‹å®ï¼‰===
{evidence_text if evidence_text else "ï¼ˆæ— ç»“æ„åŒ–è¯æ®ï¼Œè¯·åŸºäºå¤§çº²å†…å®¹å†™ä½œï¼Œä¸è¦ç¼–é€ æ•°æ®ï¼‰"}

=== ä¿¡æ¯å·®åˆ†æ ===
{gap_text if gap_text else "ï¼ˆæ— ä¿¡æ¯å·®åˆ†æï¼‰"}

=== å¤šè§†è§’å‚è€ƒ ===
{forum_text}

è¯·æ’°å†™1500-2500å­—çš„å…¬ä¼—å·æ–‡ç« ï¼ˆMarkdown æ ¼å¼ï¼‰ã€‚"""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt[:20000]},
            ],
            temperature=0.7,
            timeout=180,
        )
        content = response.choices[0].message.content.strip()

        # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹
        if content.startswith("```markdown"):
            content = content[len("```markdown"):].strip()
        if content.startswith("```"):
            content = content[3:].strip()
        if content.endswith("```"):
            content = content[:-3].strip()

        return content

    except Exception as e:
        logger.error(f"æ–‡ç« ç”Ÿæˆå¤±è´¥: {e}")
        return ""


def _import_docx_renderer():
    """ç›´æ¥åŠ è½½ docx_renderer æ¨¡å—ï¼Œç»•è¿‡ ReportEngine/__init__ çš„é‡ä¾èµ–é“¾"""
    import importlib.util
    spec = importlib.util.spec_from_file_location(
        "docx_renderer",
        str(PROJECT_ROOT / "ReportEngine" / "renderers" / "docx_renderer.py"),
    )
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)
    return mod.DocxRenderer


def render_docx(markdown_text: str, output_path: str) -> Optional[str]:
    """å°† Markdown æ–‡æœ¬æ¸²æŸ“ä¸º .docx"""
    try:
        DocxRenderer = _import_docx_renderer()
        renderer = DocxRenderer()
        renderer.render_from_markdown(markdown_text)
        renderer.save(output_path)
        return output_path

    except Exception as e:
        logger.error(f"DOCX æ¸²æŸ“å¤±è´¥: {e}")
        return None


def run_quill(date_str: Optional[str] = None) -> Optional[str]:
    """
    æ‰§è¡Œ Quillï¼šç”Ÿæˆæ–‡ç«  â†’ docx â†’ å‘é€ Telegramã€‚
    è¿”å› .docx æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› Noneã€‚
    """
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    logger.info(f"=== Quill å¼€å§‹ | date={date_str} ===")

    # 0. æ£€æŸ¥æ¯æ—¥å‘å¸ƒé¢åº¦
    state = load_state()
    if not can_publish_free(state):
        logger.warning("ä»Šæ—¥å…è´¹æ–‡ç« é¢åº¦å·²ç”¨å®Œï¼Œè·³è¿‡")
        return None

    # 1. åŠ è½½ Sage åˆ†æ
    analysis = load_sage_analysis(date_str)
    if not analysis:
        logger.warning("æ—  Sage åˆ†ææ•°æ®ï¼ŒQuill è·³è¿‡")
        return None

    selected = analysis.get("selected_topic", {})
    topic = selected.get("topic", "")
    if not topic:
        logger.warning("Sage æœªé€‰å®šè¯é¢˜ï¼Œè·³è¿‡")
        return None

    logger.info(f">>> è¯é¢˜: {topic}")

    # 2. ç”Ÿæˆæ–‡ç« 
    logger.info(">>> ç”Ÿæˆæ–‡ç« ...")
    article_md = generate_article_markdown(analysis)
    if not article_md or len(article_md) < 500:
        logger.warning(f"æ–‡ç« å†…å®¹è¿‡çŸ­ ({len(article_md)} å­—)ï¼Œè·³è¿‡")
        return None

    logger.info(f">>> æ–‡ç« ç”Ÿæˆå®Œæˆ: {len(article_md)} å­—")

    # 3. ä¿å­˜ Markdown å¤‡ä»½
    md_backup = PROJECT_ROOT / "pipeline" / "drafts" / f"{date_str}-article.md"
    md_backup.parent.mkdir(parents=True, exist_ok=True)
    with open(md_backup, "w", encoding="utf-8") as f:
        f.write(article_md)

    # 4. æ¸²æŸ“ docx
    docx_path = str(PROJECT_ROOT / "pipeline" / "drafts" / f"{date_str}-article.docx")
    logger.info(">>> æ¸²æŸ“ DOCX...")
    result = render_docx(article_md, docx_path)
    if not result:
        logger.error("DOCX æ¸²æŸ“å¤±è´¥")
        return None

    logger.info(f">>> DOCX å·²ä¿å­˜: {docx_path}")

    # 5. å‘é€åˆ° Telegram
    # æå–æ ‡é¢˜ï¼ˆMarkdown ç¬¬ä¸€è¡Œ # å¼€å¤´ï¼‰
    title = topic
    for line in article_md.split("\n"):
        line = line.strip()
        if line.startswith("# "):
            title = line[2:].strip()
            break

    caption = f"ğŸ“„ {title}\n\n{article_md[:200]}..."
    logger.info(">>> å‘é€åˆ° Telegram...")
    sent = send_document(docx_path, caption=caption)
    if sent:
        logger.info(">>> Telegram å‘é€æˆåŠŸ")
    else:
        logger.warning(">>> Telegram å‘é€å¤±è´¥ï¼ˆæ–‡ç« å·²ä¿å­˜ï¼Œå¯æ‰‹åŠ¨å‘é€ï¼‰")

    # 6. ç”Ÿæˆä»˜è´¹åŠ æ–™ premium-addon
    _generate_premium_addon(analysis, date_str, title)

    # 7. è§¦å‘ wechat-publisher åˆ›å»ºå…¬ä¼—å·è‰ç¨¿
    _trigger_wechat_publisher(docx_path)

    # 8. æ›´æ–°å‘å¸ƒè®¡æ•°
    state = load_state()
    increment_publish_count(state)
    save_state(state)

    logger.info(f"=== Quill å®Œæˆ | {docx_path} ===")
    return docx_path


def _generate_premium_addon(analysis: Dict, date_str: str, title: str):
    """ç”Ÿæˆä»˜è´¹åŠ æ–™ premium-addon.mdï¼ˆ300-800å­—ï¼šæ•°æ®è¡¨+è¡ŒåŠ¨æ¸…å•+èµ„æºé“¾æ¥ï¼‰"""
    from openai import OpenAI

    api_key = settings.REPORT_ENGINE_API_KEY or settings.INSIGHT_ENGINE_API_KEY
    base_url = settings.REPORT_ENGINE_BASE_URL or settings.INSIGHT_ENGINE_BASE_URL
    model = settings.REPORT_ENGINE_MODEL_NAME or settings.INSIGHT_ENGINE_MODEL_NAME or "qwen-max"

    if not api_key:
        logger.info("æ—  LLM API Keyï¼Œè·³è¿‡ premium-addon ç”Ÿæˆ")
        return

    selected = analysis.get("selected_topic", {})
    evidence = selected.get("evidence", [])
    info_gap = analysis.get("info_gap_analysis", {})
    outline = selected.get("outline", [])

    evidence_text = ""
    for ev in evidence:
        evidence_text += f"- [{ev.get('source_title', '')}]({ev.get('source_url', '')}): {ev.get('quote', '')}\n"
        evidence_text += f"  äº‹å®: {', '.join(ev.get('verifiable_facts', []))}\n"

    prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½"ä¼šå‘˜åŠ æ–™"å†…å®¹ï¼ˆMarkdown æ ¼å¼ï¼Œ300-800å­—ï¼‰ã€‚

è¯é¢˜ï¼š{title}
ä¿¡æ¯å·®æ´å¯Ÿï¼š{info_gap.get('gap_insight', '')}

è¯æ®æ¥æºï¼š
{evidence_text}

è¦æ±‚è¾“å‡ºç»“æ„ï¼š
## ğŸ“Š æ•°æ®å¯¹æ¯”è¡¨
ï¼ˆç”¨ Markdown è¡¨æ ¼ï¼Œæµ·å¤– vs å›½å†… å¯¹æ¯”å…³é”®æŒ‡æ ‡ï¼‰

## âœ… è¡ŒåŠ¨æ¸…å•
ï¼ˆ5æ¡å¯æ‰§è¡Œæ­¥éª¤ï¼Œæ¯æ¡1å¥è¯ï¼Œå…·ä½“å¯æ“ä½œï¼‰

## ğŸ”— å»¶ä¼¸èµ„æº
ï¼ˆ3-5ä¸ªé“¾æ¥ï¼Œæ¥è‡ªè¯æ®çš„åŸå§‹ URLï¼Œé™„ç®€è¦è¯´æ˜ï¼‰

## ğŸ’¡ æ·±åº¦æ´å¯Ÿ
ï¼ˆ1æ®µ100å­—çš„ç‹¬å®¶åˆ†æï¼Œåªåœ¨ä¼šå‘˜ç‰ˆå‡ºç°ï¼‰

åªè¾“å‡º Markdownï¼Œä¸è¦ä»£ç å—åŒ…è£¹ã€‚"""

    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            timeout=60,
        )
        addon_md = response.choices[0].message.content.strip()
        if addon_md.startswith("```"):
            addon_md = addon_md.split("\n", 1)[-1]
        if addon_md.endswith("```"):
            addon_md = addon_md[:-3].strip()

        # ä¿å­˜
        addon_path = PROJECT_ROOT / "pipeline" / "drafts" / f"{date_str}-premium-addon.md"
        addon_path.parent.mkdir(parents=True, exist_ok=True)
        with open(addon_path, "w", encoding="utf-8") as f:
            f.write(f"# ä¼šå‘˜åŠ æ–™ | {title}\n\n{addon_md}")

        logger.info(f">>> Premium addon å·²ä¿å­˜: {addon_path} ({len(addon_md)} å­—)")

        # å‘é€åˆ° Premium Telegram é¢‘é“ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        paid_chat_id = getattr(settings, "PAID_TELEGRAM_CHAT_ID", None) or os.getenv("PAID_TELEGRAM_CHAT_ID", "")
        if paid_chat_id:
            from telegram_sender import send_message
            send_message(f"ğŸ”’ ä¼šå‘˜åŠ æ–™ | {title}\n\n{addon_md[:3000]}", chat_id=paid_chat_id)
            logger.info(">>> Premium addon å·²å‘é€åˆ°ä¼šå‘˜é¢‘é“")
        else:
            logger.info(">>> PAID_TELEGRAM_CHAT_ID æœªé…ç½®ï¼Œè·³è¿‡ä¼šå‘˜é¢‘é“æŠ•é€’")

    except Exception as e:
        logger.warning(f"Premium addon ç”Ÿæˆå¤±è´¥: {e}")


def _trigger_wechat_publisher(docx_path: str):
    """ç›´æ¥è°ƒç”¨ wechat_publisher_cron.py --file åˆ›å»ºå…¬ä¼—å·è‰ç¨¿"""
    import subprocess
    wechat_script = Path.home() / "CascadeProjects" / "wechat_publisher_cron.py"
    if not wechat_script.exists():
        logger.info("wechat_publisher_cron.py ä¸å­˜åœ¨ï¼Œè·³è¿‡å…¬ä¼—å·å‘å¸ƒ")
        return
    try:
        logger.info(">>> è§¦å‘ wechat-publisher åˆ›å»ºå…¬ä¼—å·è‰ç¨¿...")
        result = subprocess.run(
            ["/usr/bin/python3", str(wechat_script), "--file", docx_path],
            capture_output=True, text=True, timeout=120,
            cwd=str(wechat_script.parent),
        )
        if result.returncode == 0:
            logger.info(">>> wechat-publisher æ‰§è¡ŒæˆåŠŸ")
            if result.stdout:
                for line in result.stdout.strip().split("\n")[-5:]:
                    logger.info(f"    {line}")
        else:
            logger.warning(f">>> wechat-publisher è¿”å›ç  {result.returncode}")
            if result.stderr:
                logger.warning(f"    {result.stderr[:300]}")
    except subprocess.TimeoutExpired:
        logger.warning(">>> wechat-publisher è¶…æ—¶ (120s)")
    except Exception as e:
        logger.warning(f">>> wechat-publisher è°ƒç”¨å¤±è´¥: {e}")


def main():
    parser = argparse.ArgumentParser(description="Quill Runner - æ–‡ç« ç”Ÿæˆ")
    parser.add_argument("--date", type=str, help="ç›®æ ‡æ—¥æœŸ (YYYYMMDD)")
    args = parser.parse_args()

    result = run_quill(date_str=args.date)
    if result:
        print(f"Quill å®Œæˆ: {result}")
    else:
        print("Quill å®Œæˆ: æ— è¾“å‡º")


if __name__ == "__main__":
    main()
