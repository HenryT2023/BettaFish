# -*- coding: utf-8 -*-
"""
Growth Runner â€” å¢é•¿é—­ç¯ Agent

èŒè´£ï¼š
1. è¯»å–å½“å¤© Quill äº§å‡ºçš„æ–‡ç« 
2. ç”Ÿæˆï¼šæ ‡é¢˜ A/B æµ‹è¯•å€™é€‰ã€æœ‹å‹åœˆ/ç¤¾ç¾¤è½¬å‘æ–‡æ¡ˆã€ä»˜è´¹ CTAã€æ¬¡æ—¥é€‰é¢˜å»ºè®®
3. ç»“æœå‘é€åˆ° Telegram

ç”¨æ³•ï¼š
    python growth_runner.py                    # è‡ªåŠ¨ä½¿ç”¨å½“å¤©æ–‡ç« 
    python growth_runner.py --date 20260213    # æŒ‡å®šæ—¥æœŸ
"""
from __future__ import annotations

import argparse
import os
import json
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict

from loguru import logger

from config import settings

PROJECT_ROOT = Path(__file__).resolve().parent


def load_article(date_str: str) -> Optional[str]:
    """åŠ è½½å½“å¤©çš„å…è´¹æ–‡ç«  Markdown"""
    article_path = PROJECT_ROOT / "pipeline" / "drafts" / f"{date_str}-article.md"
    if not article_path.exists():
        logger.warning(f"æ–‡ç« ä¸å­˜åœ¨: {article_path}")
        return None
    with open(article_path, "r", encoding="utf-8") as f:
        return f.read()


def load_analysis(date_str: str) -> Dict:
    """åŠ è½½å½“å¤©çš„ Sage åˆ†æ JSON"""
    json_path = PROJECT_ROOT / "pipeline" / "sage" / f"{date_str}-analysis.json"
    if not json_path.exists():
        return {}
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)


def generate_growth_pack(article_md: str, analysis: Dict) -> Optional[str]:
    """
    è°ƒç”¨ LLM ç”Ÿæˆå¢é•¿ç´ æåŒ…ï¼š
    - 3 ç»„æ ‡é¢˜ A/B æµ‹è¯•å€™é€‰
    - 3 æ¡æœ‹å‹åœˆ/ç¤¾ç¾¤è½¬å‘çŸ­æ–‡æ¡ˆ
    - 2 æ¡ä»˜è´¹ CTA æ–‡æ¡ˆ
    - æ¬¡æ—¥é€‰é¢˜å»ºè®®
    """
    from openai import OpenAI

    api_key = settings.REPORT_ENGINE_API_KEY or settings.INSIGHT_ENGINE_API_KEY
    base_url = settings.REPORT_ENGINE_BASE_URL or settings.INSIGHT_ENGINE_BASE_URL
    model = settings.REPORT_ENGINE_MODEL_NAME or settings.INSIGHT_ENGINE_MODEL_NAME or "qwen-max"

    if not api_key:
        logger.error("æ— å¯ç”¨ LLM API Key")
        return None

    client = OpenAI(api_key=api_key, base_url=base_url)

    selected = analysis.get("selected_topic", {})
    topic = selected.get("topic", "")
    evidence = selected.get("evidence", [])
    info_gap = analysis.get("info_gap_analysis", {})

    # æå–æ–‡ç« æ ‡é¢˜
    title = topic
    for line in article_md.split("\n"):
        line = line.strip()
        if line.startswith("# "):
            title = line[2:].strip()
            break

    evidence_facts = []
    for ev in evidence:
        evidence_facts.extend(ev.get("verifiable_facts", []))

    prompt = f"""ä½ æ˜¯ã€Œä¸œæ—ºæ•°è´¸ã€å…¬ä¼—å·çš„å¢é•¿è¿è¥ä¸“å®¶ã€‚

ä»Šå¤©çš„æ–‡ç« æ ‡é¢˜ï¼š{title}
è¯é¢˜ï¼š{topic}
ä¿¡æ¯å·®æ´å¯Ÿï¼š{info_gap.get('gap_insight', '')}
å…³é”®æ•°æ®ï¼š{', '.join(evidence_facts[:10])}

è¯·ç”Ÿæˆä»¥ä¸‹å¢é•¿ç´ æï¼ˆçº¯ Markdown æ ¼å¼ï¼‰ï¼š

## ğŸ“Œ æ ‡é¢˜ A/B æµ‹è¯•ï¼ˆ3ç»„ï¼‰
æ¯ç»„åŒ…å« Aç‰ˆï¼ˆç†æ€§ï¼‰å’Œ Bç‰ˆï¼ˆæ„Ÿæ€§ï¼‰ï¼Œ20å­—ä»¥å†…ï¼Œé™„ç®€è¦ç†ç”±ã€‚

## ğŸ“± æœ‹å‹åœˆ/ç¤¾ç¾¤è½¬å‘æ–‡æ¡ˆï¼ˆ3æ¡ï¼‰
æ¯æ¡ 50-80 å­—ï¼Œé€‚åˆç›´æ¥å¤åˆ¶ç²˜è´´ã€‚è¦æœ‰ä¿¡æ¯å·®æ„Ÿã€å¼•å‘å¥½å¥‡ã€‚

## ğŸ’° ä»˜è´¹ CTA æ–‡æ¡ˆï¼ˆ2æ¡ï¼‰
æ¯æ¡ 30-50 å­—ï¼Œå¼•å¯¼è¯»è€…è¿›å…¥ä¼šå‘˜é¢‘é“ã€‚è‡ªç„¶ä¸ç”Ÿç¡¬ã€‚

## ğŸ”® æ¬¡æ—¥é€‰é¢˜å»ºè®®ï¼ˆ3ä¸ªï¼‰
åŸºäºä»Šå¤©è¯é¢˜çš„å»¶ä¼¸æ–¹å‘ï¼Œæ¯ä¸ªé™„ç®€è¦ç†ç”±ï¼ˆ20å­—ï¼‰ã€‚

åªè¾“å‡º Markdownï¼Œä¸è¦ä»£ç å—åŒ…è£¹ã€‚"""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            timeout=60,
        )
        content = response.choices[0].message.content.strip()
        if content.startswith("```"):
            content = content.split("\n", 1)[-1]
        if content.endswith("```"):
            content = content[:-3].strip()
        return content
    except Exception as e:
        logger.error(f"å¢é•¿ç´ æåŒ…ç”Ÿæˆå¤±è´¥: {e}")
        return None


def run_growth(date_str: Optional[str] = None) -> Optional[str]:
    """
    æ‰§è¡Œ Growthï¼šç”Ÿæˆå¢é•¿ç´ æåŒ… â†’ ä¿å­˜ â†’ å‘é€ Telegramã€‚
    è¿”å›ä¿å­˜è·¯å¾„ï¼Œå¤±è´¥è¿”å› Noneã€‚
    """
    if date_str is None:
        date_str = datetime.now().strftime("%Y%m%d")

    logger.info(f"=== Growth å¼€å§‹ | date={date_str} ===")

    # 1. åŠ è½½æ–‡ç« 
    article_md = load_article(date_str)
    if not article_md:
        logger.warning("æ— å½“å¤©æ–‡ç« ï¼ŒGrowth è·³è¿‡")
        return None

    # 2. åŠ è½½åˆ†æ
    analysis = load_analysis(date_str)

    # 3. ç”Ÿæˆå¢é•¿ç´ æåŒ…
    logger.info(">>> ç”Ÿæˆå¢é•¿ç´ æåŒ…...")
    growth_md = generate_growth_pack(article_md, analysis)
    if not growth_md:
        logger.warning("å¢é•¿ç´ æåŒ…ç”Ÿæˆå¤±è´¥")
        return None

    logger.info(f">>> å¢é•¿ç´ æåŒ…ç”Ÿæˆå®Œæˆ: {len(growth_md)} å­—")

    # 4. ä¿å­˜
    output_path = PROJECT_ROOT / "pipeline" / "growth" / f"{date_str}-growth.md"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(f"# å¢é•¿ç´ æåŒ… | {date_str}\n\n{growth_md}")

    logger.info(f">>> å·²ä¿å­˜: {output_path}")

    # 5. å‘é€åˆ° Telegram
    try:
        from telegram_sender import send_message
        # æˆªå–å‰ 3000 å­—ç¬¦ï¼ˆTelegram æ¶ˆæ¯é™åˆ¶ 4096ï¼‰
        msg = f"ğŸ“ˆ å¢é•¿ç´ æåŒ… | {date_str}\n\n{growth_md[:3000]}"
        send_message(msg)
        logger.info(">>> Telegram å‘é€æˆåŠŸ")
    except Exception as e:
        logger.warning(f"Telegram å‘é€å¤±è´¥: {e}")

    logger.info(f"=== Growth å®Œæˆ | {output_path} ===")
    return str(output_path)


def main():
    parser = argparse.ArgumentParser(description="Growth Runner - å¢é•¿ç´ æåŒ…")
    parser.add_argument("--date", type=str, help="ç›®æ ‡æ—¥æœŸ (YYYYMMDD)")
    args = parser.parse_args()

    result = run_growth(date_str=args.date)
    if result:
        print(f"Growth å®Œæˆ: {result}")
    else:
        print("Growth å®Œæˆ: æ— è¾“å‡º")


if __name__ == "__main__":
    main()
